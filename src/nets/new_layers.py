
from escnn.group import *
from escnn.gspaces import *
from escnn.nn import FieldType
from escnn.nn import GeometricTensor
from escnn.nn import R2Conv
from escnn.nn.modules.equivariant_module import EquivariantModule
from escnn.nn import SequentialModule
import escnn.nn as nn  # to avoid shadowing torch.nn as nn
import escnn.gspaces as gspaces
import torch
import torch.nn.functional as F

from typing import List, Tuple, Any

import numpy as np

from collections import defaultdict

from torch.nn import Parameter

from escnn.gspaces import *
from escnn.nn import FieldType
from escnn.nn import GeometricTensor



import numpy as np


def _build_kernel(G: Group, irrep: List[tuple]):
    kernel = []
    
    for irr in irrep:
        irr = G.irrep(*irr)
        
        c = int(irr.size//irr.sum_of_squares_constituents)
        k = irr(G.identity)[:, :c] * np.sqrt(irr.size)
        kernel.append(k.T.reshape(-1))
    
    kernel = np.concatenate(kernel)
    return kernel
    
'''
class AdaptiveFourierPointwiseSO2(torch.nn.Module):
    """
    Adaptive Fourier-based nonlinearity for SO(2) with per-location sampling matrices A(x).

    Pipeline at each spatial location x:
        s(x) = A(x) @ f̂(x)          # inverse FT samples at N angles
        y(x) = σ(s(x))               # pointwise nonlinearity
        f̂'(x) = (1/N) A(x)^T @ y(x) # fast pseudo-inverse (rows ~ orthonormal)

    A(x) is generated by an equivariant sampling branch (one R2Conv -> type-1), then
    N angles are built as θ_i(x) = θ0(x) + Δ_i, with fixed offsets Δ_i to preserve equivariance.
    """
    def __init__(
        self,
        space: gspaces.Rot2dOnR2,
        channels: int,
        irreps,                          # the same object you pass to your FourierPointwise
        *,
        function: str = 'p_elu',
        inplace: bool = True,
        normalize: bool = True,
        N: int = 8,
        offsets: torch.Tensor | None = None,
        input_type_irreps: FieldType | None = None,
    ):
        super().__init__()
        self.space = space
        G = self.space.fibergroup

        # Build the representation used in the nonlinearity (regular/quotient in SO(2) case).
        # Must match your Fourier layer construction.
        self.rho = G.spectral_regular_representation(*irreps)
        self.rho_out = self.rho  # same bandlimit; extend if you need out_irreps

        # ESCNN type metadata
        self.in_type = FieldType(self.space, [self.rho] * channels)
        self.out_type = FieldType(self.space, [self.rho_out] * channels)

        # Pointwise function (use non-deprecated funcs, avoid in-place for safety with autograd)
        if function == 'p_relu':
            self._function = F.relu if not inplace else torch.relu_
        elif function == 'p_elu':
            self._function = F.elu if not inplace else torch.elu_
        elif function == 'p_sigmoid':
            self._function = torch.sigmoid  # no in-place variant
        elif function == 'p_tanh':
            self._function = torch.tanh     # no in-place variant
        else:
            raise ValueError(f'Function "{function}" not recognized!')

        # Dirac kernel in rep space: δ̂, same object your fixed-grid FourierPointwise uses
        self.kernel = _build_kernel(G, irreps)  # (F, 1) after reshape below
        assert self.kernel.shape[0] == self.rho.size, "kernel and representation size mismatch"
        if normalize:
            self.kernel = self.kernel / np.linalg.norm(self.kernel)
        self.register_buffer('kernel_t', torch.tensor(self.kernel.reshape(-1, 1), dtype=torch.get_default_dtype()))

        # Sampling spec
        self.N = int(N)
        if offsets is None:
            offs = torch.linspace(0, 2 * torch.pi, self.N + 1)[:-1]
        else:
            offs = offsets.detach()
            if offs.shape[0] != self.N:
                raise ValueError("offsets length must equal N")
        self.register_buffer('offsets', offs)  # shape (N,)

        # One-conv equivariant sampling branch -> type-1 output (2 channels) to extract θ via atan2
        # Your draft wrongly used out_type=input_type_irreps which is not a type-1 vector. 
        if input_type_irreps is None:
            input_type_irreps = self.in_type
        vec_type = FieldType(self.space, [self.space.fibergroup.irrep(1)])  # 2D real rep rotates like a vector
        self.sampling_branch = SequentialModule(
            R2Conv(input_type=input_type_irreps, out_type=vec_type, kernel_size=1, bias=False)
        )

    # ---------- grid construction ----------

    @torch.no_grad()
    def _angles_from_vector(self, v: torch.Tensor) -> torch.Tensor:
        """
        v: (B, 2, H, W) type-1 field
        returns thetas: (B, H, W) base angles in [−π, π]
        """
        # small floor to avoid NaN atan2 at zero
        vx, vy = v[:, 0], v[:, 1]
        return torch.atan2(vy, vx)

    def _build_A_rows_batch(self, thetas: torch.Tensor) -> torch.Tensor:
        """
        Build per-location sampling matrix rows using rho(g) @ δ̂, which
        automatically respects the internal column ordering of self.rho.

        thetas: (B, H, W, N)
        returns A: (B, H, W, N, F)
        """
        B, H, W, N = thetas.shape
        F = self.rho.size
        device = thetas.device
        A = torch.empty((B, H, W, N, F), dtype=self.kernel_t.dtype, device=device)

        # This uses python-level loops over N (and B,H,W implicit through indexing)
        # because escnn’s rho(g) returns numpy arrays per element. Correct > fast.
        for n in range(N):
            theta_n = thetas[..., n]  # (B, H, W)
            # We have different θ per pixel. Build A row per pixel by calling rho(gθ) @ δ̂.
            # Unavoidably a loop over all pixels if we call rho() per element; vectorize later if needed.
            for b in range(B):
                for h in range(H):
                    for w in range(W):
                        g = self.space.fibergroup.element(float(theta_n[b, h, w]))
                        # rho(g): (F x F) numpy, kernel: (F x 1) torch; convert rho to torch
                        rho_g = torch.tensor(self.rho(g), dtype=self.kernel_t.dtype, device=device)
                        row = (rho_g @ self.kernel_t).squeeze(-1)  # (F,)
                        A[b, h, w, n] = row
        return A

    # ---------- main forward ----------

    def forward(self, input: GeometricTensor) -> GeometricTensor:
        """
        input: GeometricTensor with type == self.in_type
        output: GeometricTensor with type == self.out_type
        """
        assert input.type == self.in_type, "input type mismatch"

        B, Cin, H, W = input.tensor.shape
        Fsize = self.rho.size

        # coefficient field view (B, C, F, H, W)
        x_hat = input.tensor.view(B, Cin, Fsize, H, W)

        # 1) predict base direction (type-1 field) and convert to base angle per location
        v = self.sampling_branch(x_hat).tensor  # (B, 2, H, W)
        theta0 = self._angles_from_vector(v)    # (B, H, W)

        # 2) add fixed offsets to get N sample angles per location
        thetas = theta0[..., None] + self.offsets.view(1, 1, 1, self.N)  # (B, H, W, N)

        # 3) build A(x) : (B, H, W, N, F)
        A = self._build_A_rows_batch(thetas)

        # 4) samples s = A @ f̂  -> (B, C, N, H, W)
        # permute A to (B, N, H, W, F) then einsum with (B, C, F, H, W)
        s = torch.einsum('bnhwf,bcfhw->bcnhw', A.permute(0, 3, 1, 2, 4), x_hat)

        # 5) pointwise nonlinearity
        y = self._function(s)

        # 6) backprojection with fast pseudo-inverse ≈ (1/N) A^T
        # A^T: (B, F, H, W, N)
        AT = A.permute(0, 4, 1, 2, 3)
        y_hat = torch.einsum('bfhwn,bcnhw->bcfhw', AT, y) / float(self.N)

        out = y_hat.view(B, self.out_type.size, H, W)
        return GeometricTensor(out, self.out_type, input.coords)

    # ---- utilities ----

    def evaluate_output_shape(self, input_shape: Tuple[int, ...]) -> Tuple[int, ...]:
        assert len(input_shape) == 4 and input_shape[1] == self.in_type.size
        b, _, h, w = input_shape
        return (b, self.out_type.size, h, w)

    def check_equivariance(self, atol: float = 1e-5, rtol: float = 2e-2, assert_raise: bool = True) -> List[Tuple[Any, float]]:
    
        c = self.in_type.size
        B = 128
        x = torch.randn(B, c, *[3]*self.space.dimensionality)

        # since we mostly use non-linearities like relu or eu,l we make sure the average value of the features is
        # positive, such that, when we test inputs with only frequency 0 (or only low frequencies), the output is not
        # zero everywhere
        x = x.view(B, len(self.in_type), self.rho.size, *[3]*self.space.dimensionality)
        p = 0
        for irr in self.rho.irreps:
            irr = self.space.irrep(*irr)
            if irr.is_trivial():
                x[:, :, p] = x[:, :, p].abs()
            p+=irr.size

        x = x.view(B, self.in_type.size, *[3]*self.space.dimensionality)

        errors = []

        # for el in self.space.testing_elements:
        for _ in range(100):
            
            el = self.space.fibergroup.sample()
    
            x1 = GeometricTensor(x.clone(), self.in_type)
            x2 = GeometricTensor(x.clone(), self.in_type).transform_fibers(el)

            out1 = self(x1).transform_fibers(el)
            out2 = self(x2)

            out1 = out1.tensor.view(B, len(self.out_type), self.rho_out.size, *out1.shape[2:]).detach().numpy()
            out2 = out2.tensor.view(B, len(self.out_type), self.rho_out.size, *out2.shape[2:]).detach().numpy()

            errs = np.linalg.norm(out1 - out2, axis=2).reshape(-1)
            errs[errs < atol] = 0.
            norm = np.sqrt(np.linalg.norm(out1, axis=2).reshape(-1) * np.linalg.norm(out2, axis=2).reshape(-1))
            
            relerr = errs / norm

            # print(el, errs.max(), errs.mean(), relerr.max(), relerr.min())

            if assert_raise:
                assert relerr.mean()+ relerr.std() < rtol, \
                    'The error found during equivariance check with element "{}" is too high: max = {}, mean = {}, std ={}' \
                        .format(el, relerr.max(), relerr.mean(), relerr.std())

            # errors.append((el, errs.mean()))
            errors.append(relerr)

        # return errors
        return np.concatenate(errors).reshape(-1)


'''
class FourierPointwiseInnerBn(EquivariantModule):


    def __init__(self, in_type: FieldType):
        pass

    def forward(self, input: GeometricTensor) -> GeometricTensor:
        pass

    def __init__(
            self,
            gspace: GSpace,
            channels: int,
            irreps: List,
            *grid_args,
            function: str = 'p_relu',
            inplace: bool = True,
            out_irreps: List = None,
            normalize: bool = True,
            **grid_kwargs
    ):

        assert isinstance(gspace, GSpace)
        
        super(FourierPointwiseInnerBn, self).__init__()

        self.space = gspace
        
        G: Group = gspace.fibergroup
        
        self.rho = G.spectral_regular_representation(*irreps, name=None)

        self.in_type = FieldType(self.space, [self.rho] * channels)

        if out_irreps is None:
            # the representation in input is preserved
            self.out_type = self.in_type
            self.rho_out = self.rho
        else:
            self.rho_out = G.spectral_regular_representation(*out_irreps, name=None)
            self.out_type = FieldType(self.space, [self.rho_out] * channels)

        # retrieve the activation function to apply
        if function == 'p_relu':
            self._function = F.relu_ if inplace else F.relu
        elif function == 'p_elu':
            self._function = F.elu_ if inplace else F.elu
        elif function == 'p_sigmoid':
            self._function = torch.sigmoid_ if inplace else F.sigmoid
        elif function == 'p_tanh':
            self._function = torch.tanh_ if inplace else F.tanh
        else:
            raise ValueError('Function "{}" not recognized!'.format(function))
        
        kernel = _build_kernel(G, irreps)
        assert kernel.shape[0] == self.rho.size

        if normalize:
            kernel = kernel / np.linalg.norm(kernel)
        kernel = kernel.reshape(-1, 1)
        
        grid = G.grid(*grid_args, **grid_kwargs)
        
        A = np.concatenate(
            [
                self.rho(g) @ kernel
                for g in grid
            ], axis=1
        ).T

        if out_irreps is not None:

            _missing_input_irreps = list(set(irreps).difference(set(out_irreps)))
            rho_out_extended = G.spectral_regular_representation(*out_irreps, *_missing_input_irreps, name=None)
            kernel_out = _build_kernel(G, out_irreps + _missing_input_irreps)
            assert kernel_out.shape[0] == rho_out_extended.size

            if normalize:
                kernel_out = kernel_out / np.linalg.norm(kernel_out)
            kernel_out = kernel_out.reshape(-1, 1)

            A_out = np.concatenate(
                [
                    rho_out_extended(g) @ kernel_out
                    for g in grid
                ], axis=1
            ).T
        else:
            A_out = A
            _missing_input_irreps = []
            rho_out_extended = self.rho_out

        eps = 1e-8
        Ainv = np.linalg.inv(A_out.T @ A_out + eps * np.eye(rho_out_extended.size)) @ A_out.T

        if out_irreps is not None:
            Ainv = Ainv[:self.rho_out.size, :]

        self.register_buffer('A', torch.tensor(A, dtype=torch.get_default_dtype()))
        self.register_buffer('Ainv', torch.tensor(Ainv, dtype=torch.get_default_dtype()))

        self.bn = torch.nn.BatchNorm3d(num_features=channels)
        
    def forward(self, input: GeometricTensor) -> GeometricTensor:
        r"""

        Applies the pointwise activation function on the input fields

        Args:
            input (GeometricTensor): the input feature map

        Returns:
            the resulting feature map after the non-linearities have been applied

        """

        assert input.type == self.in_type
        
        shape = input.shape
        # (B, C, r_size, H, W)
        x_hat = input.tensor.view(shape[0], len(self.in_type), self.rho.size, *shape[2:])
        
        x = torch.einsum('bcf...,gf->bcg...', x_hat, self.A)
        
        y = self.bn(x)
        y = self._function(y)

        y_hat = torch.einsum('bcg...,fg->bcf...', y, self.Ainv)

        y_hat = y_hat.reshape(shape[0], self.out_type.size, *shape[2:])

        return GeometricTensor(y_hat, self.out_type, input.coords)

    def evaluate_output_shape(self, input_shape: Tuple[int, ...]) -> Tuple[int, ...]:

        assert len(input_shape) >= 2
        assert input_shape[1] == self.in_type.size

        b, c = input_shape[:2]
        spatial_shape = input_shape[2:]

        return (b, self.out_type.size, *spatial_shape)

    def check_equivariance(self, atol: float = 1e-5, rtol: float = 2e-2, assert_raise: bool = True) -> List[Tuple[Any, float]]:
    
        c = self.in_type.size
        B = 128
        x = torch.randn(B, c, *[3]*self.space.dimensionality)

        # since we mostly use non-linearities like relu or eu,l we make sure the average value of the features is
        # positive, such that, when we test inputs with only frequency 0 (or only low frequencies), the output is not
        # zero everywhere
        x = x.view(B, len(self.in_type), self.rho.size, *[3]*self.space.dimensionality)
        p = 0
        for irr in self.rho.irreps:
            irr = self.space.irrep(*irr)
            if irr.is_trivial():
                x[:, :, p] = x[:, :, p].abs()
            p+=irr.size

        x = x.view(B, self.in_type.size, *[3]*self.space.dimensionality)

        errors = []

        # for el in self.space.testing_elements:
        for _ in range(100):
            
            el = self.space.fibergroup.sample()
    
            x1 = GeometricTensor(x.clone(), self.in_type)
            x2 = GeometricTensor(x.clone(), self.in_type).transform_fibers(el)

            out1 = self(x1).transform_fibers(el)
            out2 = self(x2)

            out1 = out1.tensor.view(B, len(self.out_type), self.rho_out.size, *out1.shape[2:]).detach().numpy()
            out2 = out2.tensor.view(B, len(self.out_type), self.rho_out.size, *out2.shape[2:]).detach().numpy()

            errs = np.linalg.norm(out1 - out2, axis=2).reshape(-1)
            errs[errs < atol] = 0.
            norm = np.sqrt(np.linalg.norm(out1, axis=2).reshape(-1) * np.linalg.norm(out2, axis=2).reshape(-1))
            
            relerr = errs / norm

            # print(el, errs.max(), errs.mean(), relerr.max(), relerr.min())

            if assert_raise:
                assert relerr.mean()+ relerr.std() < rtol, \
                    'The error found during equivariance check with element "{}" is too high: max = {}, mean = {}, std ={}' \
                        .format(el, relerr.max(), relerr.mean(), relerr.std())

            # errors.append((el, errs.mean()))
            errors.append(relerr)

        # return errors
        return np.concatenate(errors).reshape(-1)
    


class NormNonlinearityWithBN(EquivariantModule):
    
    def __init__(self, in_type: FieldType, eps=1e-7, momentum=0.1, affine=True, function: str="relu"):

        assert isinstance(in_type.gspace, GSpace)
        
        super(NormNonlinearityWithBN, self).__init__()


        self.space = in_type.gspace
        self.in_type = in_type
        self.out_type = in_type
        
        self.affine = affine

        if function == 'relu':
            self._function = F.relu
        elif function == 'elu':
            self._function = F.elu
        elif function == 'sigmoid':
            self._function = torch.sigmoid
        else:
            raise ValueError(f'Unknown norm-bn activation "{function}"')
        # group fields by their size and
        #   - check if fields of the same size are contiguous
        #   - retrieve the indices of the fields

        # number of fields of each size
        self._nfields = defaultdict(int)
        
        # indices of the channels corresponding to fields belonging to each group
        _indices = defaultdict(lambda: [])
        
        # whether each group of fields is contiguous or not
        self._contiguous = {}
        
        position = 0
        last_size = None
        for i, r in enumerate(self.in_type.representations):
            
            if r.size != last_size:
                if not r.size in self._contiguous:
                    self._contiguous[r.size] = True
                else:
                    self._contiguous[r.size] = False
            last_size = r.size
            
            _indices[r.size] += list(range(position, position + r.size))
            self._nfields[r.size] += 1
            position += r.size
        
        for size, contiguous in self._contiguous.items():
            if contiguous:
                # for contiguous fields, only the first and last indices are kept
                _indices[size] = torch.LongTensor([min(_indices[size]), max(_indices[size])+1])
            else:
                # otherwise, transform the list of indices into a tensor
                _indices[size] = torch.LongTensor(_indices[size])
                
            # register the indices tensors as parameters of this module
            self.register_buffer(f'{size}_indices', _indices[size])
            

            shape = (self._nfields[size],)
            running_var = torch.ones(shape, dtype=torch.float)
            self.register_buffer(f'{size}_running_var', running_var)

            running_mean = torch.zeros(shape, dtype=torch.float)
            self.register_buffer(f'{size}_running_mean', running_mean)
            if self.affine:
                scale = Parameter(torch.ones(shape), requires_grad=True)
                self.register_parameter(f'{size}_scale', scale)

                bias = Parameter(torch.zeros(shape), requires_grad=True)
                self.register_parameter(f'{size}_bias', bias)
        
        _indices = dict(_indices)
        
        self._order = list(_indices.keys())
        
        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))
        


        self.eps = eps
        self.momentum = momentum

    def reset_running_stats(self):
        for s in self._order:
            running_var = getattr(self, f"{s}_running_var")
            running_var.fill_(1)
            
            running_mean = getattr(self, f"{s}_running_mean")
            running_mean.fill_(0) 
        self.num_batches_tracked.zero_()

    def reset_parameters(self):
            self.reset_running_stats()
            if self.affine:
                for s in self._order:
                    getattr(self, f"{s}_scale").data.fill_(1)
                    getattr(self, f"{s}_bias").data.fill_(0)
    
    def forward(self, input: GeometricTensor) -> GeometricTensor:
        assert input.type == self.in_type

        exponential_average_factor = 0.0
        if self.training:
            self.num_batches_tracked += 1
            if self.momentum is None: 
                exponential_average_factor = 1.0 / self.num_batches_tracked.item()
            else: 
                exponential_average_factor = self.momentum

        x = input.tensor
        b, c = x.shape[:2]
        data_shape = x.shape[2:]
        output = x.clone()
        
        # iterate through all field sizes
        for r_size in self._order:
            indices = getattr(self, f"{r_size}_indices")
            running_var = getattr(self, f"{r_size}_running_var")
            running_mean = getattr(self, f"{r_size}_running_mean")
    
            if self._contiguous[r_size]:
                selected = x[:, indices[0]:indices[1], ...]
            else:
                selected = x[:, indices, ...]
            # v torchi je norma
            # (B, channels, size, H, W)
            norms = selected.pow(2).reshape(b, -1, r_size, *data_shape) \
                                .sum(dim=2, keepdim=False).add(self.eps).sqrt()
            
            if self.training:
                # (chnnales, B*H*W)
                norms_flat = norms.transpose(0, 1).reshape(self._nfields[r_size], -1)
                means = norms_flat.mean(dim=1, keepdim=False)
                # Use unbiased var if batch size > 1
                vars = norms_flat.var(dim=1, unbiased=(norms_flat.shape[1] > 1), keepdim=False)

                with torch.no_grad():
                    running_var.mul_(1 - exponential_average_factor).add_(vars, alpha=exponential_average_factor)
                    running_mean.mul_(1 - exponential_average_factor).add_(means, alpha=exponential_average_factor)
            else:
                vars = running_var
                means = running_mean
            if self.affine:
                # scale.shape = (n_channels,)
                scale = getattr(self, f"{r_size}_scale")
                # bias.shape = (n_channels,)
                bias = getattr(self, f"{r_size}_bias")
            else:
                scale = 1.
                bias = 0.
            

            pre_expand_shape = (1, -1, *([1] * len(data_shape)))
            target_shape = (b, self._nfields[r_size], *([1] * len(data_shape)))
            
            # against tiny variances
            vars_safe = vars.clamp_min(self.eps)
            multipliers = (scale / vars_safe.sqrt()).reshape(pre_expand_shape).expand(target_shape)
            means_expanded = means.reshape(pre_expand_shape).expand(target_shape)
            bias_expanded = bias if isinstance(bias, float) else bias.reshape(pre_expand_shape).expand(target_shape)

            # batch-norm the norms and apply ReLU to zero out negative norms
            norm_bn = self._function((norms - means_expanded) * multipliers + bias_expanded)

            # rescale vectors to the new norms; avoid division by zero

            scale_factor = norm_bn / norms
            
            
            # Reshape scale factor to match vector dimensions: (B, N_fields, r_size, H, W)
            scale_factor = scale_factor.unsqueeze(2).expand(b, self._nfields[r_size], r_size, *data_shape)
            scale_factor = scale_factor.reshape(b, -1, *data_shape)
            scaled = selected * scale_factor
            if self._contiguous[r_size]:
                output[:, indices[0]:indices[1], ...] = scaled
            else:
                output[:, indices, ...] = scaled
                    
        # wrap the result in a GeometricTensor
        return GeometricTensor(output, self.out_type, input.coords)

    def evaluate_output_shape(self, input_shape: Tuple[int, ...]) -> Tuple[int, ...]:

        assert len(input_shape) >= 2
        assert input_shape[1] == self.in_type.size

        b, c = input_shape[:2]
        spatial_shape = input_shape[2:]

        return (b, self.out_type.size, *spatial_shape)

    

    def check_equivariance(self, atol: float = 1e-6, rtol: float = 1e-5) -> List[Tuple[Any, float]]:
    
        c = self.in_type.size
    
        x = torch.randn(3, c, 10, 10)
    
        x = GeometricTensor(x, self.in_type)
    
        errors = []
    
        for el in self.space.testing_elements:
            out1 = self(x).transform_fibers(el)
            out2 = self(x.transform_fibers(el))
        
            errs = (out1.tensor - out2.tensor).detach().numpy()
            errs = np.abs(errs).reshape(-1)
            print(el, errs.max(), errs.mean(), errs.var())
        
            assert torch.allclose(out1.tensor, out2.tensor, atol=atol, rtol=rtol), \
                'The error found during equivariance check with element "{}" is too high: max = {}, mean = {} var ={}' \
                    .format(el, errs.max(), errs.mean(), errs.var())
        
            errors.append((el, errs.mean()))
    
        return errors
