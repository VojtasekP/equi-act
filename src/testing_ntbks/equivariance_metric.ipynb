{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb84969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from escnn import nn, gspaces\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533af484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import escnn.nn as nn\n",
    "\n",
    "@torch.inference_mode()\n",
    "def rel_err(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    x = x.reshape(y.shape[0],x.shape[0]//y.shape[0], -1)\n",
    "    \n",
    "    diff  = torch.linalg.vector_norm(x - y, dim=1)\n",
    "    denom = torch.maximum(torch.linalg.vector_norm(x, dim=1),\n",
    "                          torch.linalg.vector_norm(y, dim=1))\n",
    "    denom = torch.clamp(denom, min=1e-12)\n",
    "    return diff / denom\n",
    "\n",
    "@torch.inference_mode()\n",
    "def check_equivariance_batch(x: torch.Tensor, model, num_samples: int = 16, chunk: int = 0):\n",
    "    \"\"\"\n",
    "    Vectorized equivariance test on the *equivariant* feature map returned by model.forward_features.\n",
    "    Returns: thetas (np.ndarray), errors_per_theta (np.ndarray)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    x = x.to(device, non_blocking=True)\n",
    "\n",
    "    r2_act = getattr(model, \"r2_act\")\n",
    "    thetas = np.linspace(0.0, 2*np.pi, num_samples, endpoint=False)\n",
    "    elems  = [r2_act.fibergroup.element(float(t)) for t in thetas]\n",
    "\n",
    "    # Reference features\n",
    "    y_ref = model.forward_features(x)  # GeometricTensor\n",
    "\n",
    "    # Build transformed inputs (GeoTensor -> transform)\n",
    "    x_geo = nn.GeometricTensor(x, model.input_type)\n",
    "    x_list = [x_geo.transform(g).tensor for g in elems]\n",
    "    xb = nn.GeometricTensor(torch.cat(x_list, dim=0), model.input_type)\n",
    "\n",
    "    y_rot_tensor = model.forward_features(xb)\n",
    "\n",
    "\n",
    "\n",
    "    B = x.shape[0]\n",
    "    errs = rel_err(y_rot_tensor, y_ref).view(num_samples, B).mean(dim=1)\n",
    "    return thetas, errs.detach().cpu().numpy()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def logits_invariance_error(model, x, angles=(0, 90, 180, 270)):\n",
    "    \"\"\"\n",
    "    Relative invariance error on logits after the invariant head.\n",
    "    \"\"\"\n",
    "    from torchvision.transforms.functional import rotate, InterpolationMode\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    x = x.to(device, non_blocking=True)\n",
    "\n",
    "    base = model(x)  # (B, C)\n",
    "    errs = {}\n",
    "    for a in angles:\n",
    "        xr = rotate(x, a, interpolation=InterpolationMode.BILINEAR)\n",
    "        yr = model(xr)\n",
    "        errs[a] = rel_err(base, yr).mean().item()\n",
    "    return errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff297a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eda001c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     41\u001b[0m     ft2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mFieldType(g, [g\u001b[38;5;241m.\u001b[39mirrep(\u001b[38;5;241m2\u001b[39m)]\u001b[38;5;241m*\u001b[39mC)          \u001b[38;5;66;03m# valid: 1⊗1 -> 2\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mSequentialModule(\n\u001b[1;32m     43\u001b[0m         nn\u001b[38;5;241m.\u001b[39mR2Conv(ft_in, ft1, \u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     44\u001b[0m         nn\u001b[38;5;241m.\u001b[39mTensorProductModule(ft1, ft2, initialize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;66;03m# nn.FieldNorm(ft2, affine=True),\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;66;03m# nn.R2Conv(ft2, ft1, 3, padding=1, bias=False),  # keep width comparable\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 49\u001b[0m \u001b[43mb\u001b[49m\n\u001b[1;32m     51\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv 2 irreps\u001b[39m\u001b[38;5;124m\"\u001b[39m:        build_norm_normbn(\u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConv 3 irreps\u001b[39m\u001b[38;5;124m\"\u001b[39m:        build_norm_normbn(\u001b[38;5;241m8\u001b[39m, irreps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m }\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# --- run equivariance tests ---\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from escnn import gspaces, nn\n",
    "\n",
    "# --- group & test sampler ---\n",
    "r2_act = gspaces.rot2dOnR2(maximum_frequency=1)\n",
    "num_samples = 16\n",
    "thetas = np.linspace(0, 2*np.pi, num_samples, endpoint=True)\n",
    "elements = [r2_act.fibergroup.element(theta) for theta in thetas]\n",
    "\n",
    "g = gspaces.rot2dOnR2(N=-1)                   # SO(2)\n",
    "G = g.fibergroup\n",
    "ft_in = nn.FieldType(g, [g.trivial_repr])     # scalar input\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- model builders (same depth: conv -> act/norm -> bn -> conv) ---\n",
    "def build_norm_normbn(C=8, irreps=2):\n",
    "    irreps = [g.irrep(i) for i in range(irreps)]\n",
    "    ft = nn.FieldType(g, irreps*C)      # pure nontrivial => NormBN valid\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft, 3, padding=1, bias=True),\n",
    "        # nn.IIDBatchNorm2d(ft, affine=True),\n",
    "        # nn.NormNonLinearity(ft),\n",
    "        # nn.R2Conv(ft, ft, 3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "def build_gated_gnormbn(C=8):\n",
    "    feats = [g.irrep(0), g.irrep(1)]*C\n",
    "    gates = [g.trivial_repr]*len(feats)\n",
    "    ft_full = nn.FieldType(g, gates + feats)       # gates FIRST\n",
    "    ft_feat = nn.FieldType(g, feats)  # for batchnorm\n",
    "    len(ft_feat)\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft_full, 3, padding=1, bias=True),\n",
    "        nn.GatedNonLinearity1(ft_full, drop_gates=True),\n",
    "        # nn.FieldNorm(ft_feat, affine=True),\n",
    "        # nn.R2Conv(ft_feat, ft_feat, 3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "def build_tensorproduct_11_to_2(C=8):\n",
    "    ft1 = nn.FieldType(g, [g.irrep(1)]*C)          # uniform in\n",
    "    ft2 = nn.FieldType(g, [g.irrep(2)]*C)          # valid: 1⊗1 -> 2\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft1, 3, padding=1, bias=True),\n",
    "        nn.TensorProductModule(ft1, ft2, initialize=True),\n",
    "        # nn.FieldNorm(ft2, affine=True),\n",
    "        # nn.R2Conv(ft2, ft1, 3, padding=1, bias=False),  # keep width comparable\n",
    "    )\n",
    "\n",
    "b\n",
    "\n",
    "models = {\n",
    "    \"Conv 2 irreps\":        build_norm_normbn(8),\n",
    "    \"Conv 3 irreps\":        build_norm_normbn(8, irreps=3),\n",
    "    \"Conv 4 irreps\":        build_norm_normbn(8, irreps=4),\n",
    "    \"Conv 2 irreps, N=32\":        build_norm_normbn(32, irreps=2),\n",
    "    \"Conv 3 irreps, N=32\":        build_norm_normbn(32, irreps=3),\n",
    "    \"Conv 4 irreps, N=32\":        build_norm_normbn(32, irreps=4),\n",
    "\n",
    "}\n",
    "\n",
    "# --- run equivariance tests ---\n",
    "x = torch.randn(1, 1, 256, 256)\n",
    "x = ft_in(x).to(device)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "for name, model in models.items():\n",
    "    model = model.to(device)\n",
    "    thetas_out, errors = check_equivariance_batch(x, model, group=r2_act, num_samples=num_samples)\n",
    "    plt.hlines(np.mean(errors), xmin=0, xmax=2*np.pi, linestyles='dashed')\n",
    "    plt.plot(thetas_out, errors, marker=\"o\", ms=3, label=name)\n",
    "plt.xlabel(\"rotation angle [rad]\"); plt.ylabel(\"equivariance error\")\n",
    "plt.title(\"Equivariance error vs. rotation (SO(2))\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf76e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SO(2)_on_R2[(None, -1)]: {irrep_0 (x1), irrep_1 (x1)}(3)]\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(8, 3, 128, 128)\n",
    "r2_act = gspaces.rot2dOnR2()\n",
    "ft_in = nn.FieldType(r2_act, [r2_act.irrep(0), r2_act.irrep(1)])\n",
    "x = nn.GeometricTensor(x, type = ft_in)\n",
    "print(x.type)\n",
    "G = r2_act.fibergroup\n",
    "act = nn.FourierPointwise(r2_act, channels=2, irreps=G.bl_irreps(2), N=16)\n",
    "ft = act.out_type\n",
    "feat_type_out = act.out_type\n",
    "\n",
    "# 2) Convolution to the activation's expected input type\n",
    "conv = nn.R2Conv(ft_in, feat_type_out, kernel_size=3, padding=3, bias=True)\n",
    "\n",
    "# 3) Build scalar/vector subset FieldTypes from feat_type_out\n",
    "reps = feat_type_out.representations\n",
    "scalar_field_ids = [i for i, r in enumerate(reps) if r.size == 1]   # m = 0\n",
    "vector_field_ids = [i for i, r in enumerate(reps) if r.size > 1]    # m >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.in_type: [SO(2)_on_R2[(None, -1)]: {irrep_0 (x1), irrep_1 (x1)}(3)]\n",
      "after act type: [SO(2)_on_R2[(None, -1)]: {regular_[(0,)|(1,)|(2,)] (x2)}(10)]\n",
      "after disentangle type: [SO(2)_on_R2[(None, -1)]: {regular_[(0,)|(1,)|(2,)]_0 (x1), regular_[(0,)|(1,)|(2,)]_1 (x1), regular_[(0,)|(1,)|(2,)]_2 (x1), regular_[(0,)|(1,)|(2,)]_0 (x1), regular_[(0,)|(1,)|(2,)]_1 (x1), regular_[(0,)|(1,)|(2,)]_2 (x1)}(10)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from escnn import gspaces, nn\n",
    "\n",
    "# Fake input: 3 channels total = 1 (m=0) + 2 (m=1) -> matches [irrep(0), irrep(1)]\n",
    "x = torch.randn(8, 3, 128, 128)\n",
    "\n",
    "r2_act = gspaces.rot2dOnR2()             # continuous SO(2) on R^2\n",
    "ft_in  = nn.FieldType(r2_act, [r2_act.irrep(0), r2_act.irrep(1)])  # dims 1 + 2 = 3\n",
    "x      = nn.GeometricTensor(x, ft_in)\n",
    "\n",
    "print(\"x.in_type:\", x.type)\n",
    "\n",
    "G   = r2_act.fibergroup\n",
    "act = nn.FourierPointwise(\n",
    "    r2_act,\n",
    "    channels=2,                      # multiplicity per irrep returned below\n",
    "    irreps=G.bl_irreps(2),           # {m=0 (1D), m=1 (2D), m=2 (2D)} in real form\n",
    "    N=16,                            # angular sampling for the Fourier op\n",
    "    function='p_relu'                # be explicit; pointwise ReLU in Fourier coords\n",
    ")\n",
    "\n",
    "# IMPORTANT: convolve INTO the activation's expected INPUT type\n",
    "feat_type_in  = act.in_type\n",
    "feat_type_out = act.out_type\n",
    "\n",
    "# Map from your ft_in (3ch) -> act.in_type\n",
    "conv = nn.R2Conv(ft_in, feat_type_in, kernel_size=3, padding=1, bias=True)\n",
    "\n",
    "# Forward\n",
    "x = conv(x)\n",
    "x = act(x)\n",
    "print(\"after act type:\", x.type)     # should match feat_type_out\n",
    "\n",
    "# If you really want to \"disentangle\" into block-diagonal irrep basis,\n",
    "# build the DisentangleModule with the CURRENT type of x, not ft_in.\n",
    "dis = nn.DisentangleModule(x.type)\n",
    "x_dis = dis(x)\n",
    "print(\"after disentangle type:\", x_dis.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783a051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_in.representations[1].sum_of_squares_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bebb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO(2)|[irrep_0]:1\n",
      "SO(2)|[irrep_1]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SO(2)|[irrep_0]:1, SO(2)|[irrep_1]:2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO2 = gspaces.rot2dOnR2(maximum_frequency=8)\n",
    "O2 = gspaces.flipRot2dOnR2(maximum_frequency=2)\n",
    "\n",
    "G = SO2.fibergroup\n",
    "irreps = []\n",
    "for irr in G.irreps():\n",
    "    print(irr)\n",
    "    if irr.name == O2.trivial_repr.name:\n",
    "        continue\n",
    "    mult = int(irr.size // irr.sum_of_squares_constituents)  # 1 for 1D, 2 for 2D\n",
    "    irreps.extend([irr] * mult)\n",
    "irreps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293503cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SO(2)|[irrep_0]:1, SO(2)|[irrep_1]:2, SO(2)|[irrep_2]:2, SO(2)|[irrep_3]:2, SO(2)|[irrep_4]:2]\n",
      "[SO(2)|[irrep_0]:1, SO(2)|[irrep_1]:2, SO(2)|[irrep_2]:2, SO(2)|[irrep_3]:2, SO(2)|[irrep_4]:2]\n"
     ]
    }
   ],
   "source": [
    "from escnn import nn, gspaces\n",
    "\n",
    "\n",
    "GASAA = gspaces.rot2dOnR2(maximum_frequency=2)\n",
    "print(GASAA.irreps)\n",
    "print(GASAA.fibergroup.irreps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5fd35c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SO(2)|[irrep_0]:1\n",
      "SO(2)|[irrep_1]:2\n",
      "SO(2)|[irrep_2]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 4\n",
    "SO2 = gspaces.rot2dOnR2(maximum_frequency=L)\n",
    "O2 = gspaces.flipRot2dOnR2(maximum_frequency=2)\n",
    "s = 3\n",
    "G = SO2.fibergroup\n",
    "irreps = []\n",
    "for irr in SO2.irreps:\n",
    "    print(irr)\n",
    "    mult = int(irr.size // irr.sum_of_squares_constituents)  # 1 for 1D, 2 for 2D\n",
    "    irreps.extend([irr] * mult)\n",
    "r = nn.FieldType(SO2, irreps*L)\n",
    "tmp_cl = nn.R2Conv(r, r, s,\n",
    "                padding=1)\n",
    "tmp_cl.basisexpansion.dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d38a202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SO(2)_on_R2[(None, -1)]: {irrep_0 (x1), irrep_1 (x1), irrep_2 (x1), irrep_0 (x1), irrep_1 (x1), irrep_2 (x1), irrep_0 (x1), irrep_1 (x1), irrep_2 (x1), irrep_0 (x1), irrep_1 (x1), irrep_2 (x1)}(20)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04146d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_cl.basisexpansion.dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SO(2)_on_R2[(None, -1)]: {regular_[(0,)|(1,)|(2,)] (x1)}(5)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5373f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad467104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10add0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb77393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5385953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3c270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff00a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ae9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new file: SO2_Nets/adaptive_fourier.py\n",
    "import torch\n",
    "from escnn import nn\n",
    "\n",
    "class SamplingBranch(torch.nn.Module):\n",
    "    def __init__(self, r2_act, in_type: nn.FieldType, N: int, hidden_ch: int = 16):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # small equivariant conv stack -> outputs N scalar trivial fields that we interpret as angles on S1\n",
    "        self.net = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr]), kernel_size=3, padding=1, bias=False),\n",
    "            nn.IIDBatchNorm2d(nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr])),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.R2Conv(nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr]),\n",
    "                      nn.FieldType(r2_act, self.N * [in_type.fibergroup.trivial_repr]), kernel_size=1, padding=0, bias=True),\n",
    "        )\n",
    "        self.r2_act = r2_act\n",
    "        self.G = r2_act.fibergroup  # SO(2)\n",
    "\n",
    "    def forward(self, feat: nn.GeometricTensor, rep_rho):\n",
    "        # angles in [-pi, pi]\n",
    "        angles = torch.pi * torch.tanh(self.net(feat).tensor)  # [B, N, H, W]\n",
    "        # build A rows from angles and representation columns (quotient or regular)\n",
    "        # rep_rho expects a callable: g -> matrix R^{F}\n",
    "        A_rows = []\n",
    "        for k in range(self.N):\n",
    "            theta_k = angles[:, k:k+1, ...]  # [B,1,H,W]\n",
    "            gk = self.G.element(theta_k)     # broadcast element\n",
    "            # evaluate ρ(gk) δ̂  -> shape [B, F, H, W]\n",
    "            Ak = rep_rho(gk)                 # your helper that returns vectorized ρ(g)δ̂\n",
    "            A_rows.append(Ak)\n",
    "        A = torch.stack(A_rows, dim=1)  # [B, N, F, H, W]\n",
    "        return A\n",
    "\n",
    "class AdaptiveFourierPointwise(torch.nn.Module):\n",
    "    def __init__(self, r2_act, in_type: nn.FieldType, channels: int, irreps, function: str, N: int):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.function = function\n",
    "        self.r2_act = r2_act\n",
    "        # create a helper to map features to Fourier coeffs and back per ESCNN conventions\n",
    "        self.ft = nn.FourierTransform(in_type.gspace, irreps)\n",
    "        self.channels = channels\n",
    "\n",
    "    def forward(self, x: nn.GeometricTensor, A: torch.Tensor):\n",
    "        # x.tensor shape [B, Cin, H, W]; interpret as stacked bandlimited coeffs f̂ over channels/spatial\n",
    "        fhat = self.ft.forward(x)            # [B, C, F, H, W]\n",
    "        # Af̂: [B,N,F,H,W] x [B,C,F,H,W] -> [B,C,N,H,W]\n",
    "        y = torch.einsum('bnfhw,bcfhw->bcnhw', A, fhat)\n",
    "        # pointwise nonlinearity (ReLU/ELU) along N\n",
    "        if self.function.endswith('relu'):\n",
    "            y = torch.relu(y)\n",
    "        elif self.function.endswith('elu'):\n",
    "            y = torch.nn.functional.elu(y)\n",
    "        # (1/N)Aᵀ y: [B,C,F,H,W]\n",
    "        fhat_new = (1.0 / self.N) * torch.einsum('bnfhw,bcnhw->bcfhw', A, y)\n",
    "        # back to spatial field type\n",
    "        x_new = self.ft.inverse(fhat_new)\n",
    "        return x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bac44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SO2' object has no attribute 'trivial_repr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m pad \u001b[38;5;241m=\u001b[39m kernel_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m non_linearity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_relu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[43mSamplingBranch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr2_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# conv to feature_type before activation (as in your fixed variant)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     feature_repr \u001b[38;5;241m=\u001b[39m irreps \u001b[38;5;241m*\u001b[39m channels\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mSamplingBranch.__init__\u001b[0;34m(self, r2_act, in_type, N, hidden_ch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m=\u001b[39m N\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# small equivariant conv stack -> outputs N scalar trivial fields that we interpret as angles on S1\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequentialModule(\n\u001b[0;32m---> 11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mR2Conv(in_type, nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [\u001b[43min_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfibergroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrivial_repr\u001b[49m]), kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mIIDBatchNorm2d(nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr])),\n\u001b[1;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m     nn\u001b[38;5;241m.\u001b[39mR2Conv(nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr]),\n\u001b[1;32m     15\u001b[0m               nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr]), kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr2_act \u001b[38;5;241m=\u001b[39m r2_act\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG \u001b[38;5;241m=\u001b[39m r2_act\u001b[38;5;241m.\u001b[39mfibergroup\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SO2' object has no attribute 'trivial_repr'"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "irreps = [r2_act.irrep(0), r2_act.irrep(1), r2_act.irrep(2)]  # exclude trivial\n",
    "channels = 8\n",
    "N = 16\n",
    "kernel_size = 3\n",
    "cur_type = nn.FieldType(r2_act, [r2_act.trivial_repr] * channels)  # start from scalars\n",
    "pad = kernel_size // 2\n",
    "non_linearity = 'p_relu'\n",
    "sampler = SamplingBranch(r2_act, cur_type, N=N)\n",
    "for _ in range(2):\n",
    "    # conv to feature_type before activation (as in your fixed variant)\n",
    "    feature_repr = irreps * channels\n",
    "    feature_type = nn.FieldType(r2_act, feature_repr)\n",
    "    layers.append(nn.R2Conv(cur_type, feature_type, kernel_size=kernel_size, padding=pad, bias=False))\n",
    "\n",
    "    # build A and apply adaptive Fourier pointwise\n",
    "    act = nn.(r2_act, feature_type, channels=channels, irreps=irreps, function=non_linearity, N=N)\n",
    "    layers.append(nn.EquivariantModuleWrapper(feature_type, act, sampler))  # small wrapper that calls sampler then act\n",
    "\n",
    "    layers.append(nn.IIDBatchNorm2d(act.out_type))\n",
    "    cur_type = act.out_type\n",
    "\n",
    "nn.SequentialModule(*layers), cur_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
