{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb84969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from escnn import nn, gspaces\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533af484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import escnn.nn as nn\n",
    "\n",
    "@torch.inference_mode()\n",
    "def rel_err(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    x = x.reshape(y.shape[0],x.shape[0]//y.shape[0], -1)\n",
    "    \n",
    "    diff  = torch.linalg.vector_norm(x - y, dim=1)\n",
    "    denom = torch.maximum(torch.linalg.vector_norm(x, dim=1),\n",
    "                          torch.linalg.vector_norm(y, dim=1))\n",
    "    denom = torch.clamp(denom, min=1e-12)\n",
    "    return diff / denom\n",
    "\n",
    "@torch.inference_mode()\n",
    "def check_equivariance_batch(x: torch.Tensor, model, num_samples: int = 16, chunk: int = 0):\n",
    "    \"\"\"\n",
    "    Vectorized equivariance test on the *equivariant* feature map returned by model.forward_features.\n",
    "    Returns: thetas (np.ndarray), errors_per_theta (np.ndarray)\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    x = x.to(device, non_blocking=True)\n",
    "\n",
    "    r2_act = getattr(model, \"r2_act\")\n",
    "    thetas = np.linspace(0.0, 2*np.pi, num_samples, endpoint=False)\n",
    "    elems  = [r2_act.fibergroup.element(float(t)) for t in thetas]\n",
    "\n",
    "    # Reference features\n",
    "    y_ref = model.forward_features(x)  # GeometricTensor\n",
    "\n",
    "    # Build transformed inputs (GeoTensor -> transform)\n",
    "    x_geo = nn.GeometricTensor(x, model.input_type)\n",
    "    x_list = [x_geo.transform(g).tensor for g in elems]\n",
    "    xb = nn.GeometricTensor(torch.cat(x_list, dim=0), model.input_type)\n",
    "\n",
    "    y_rot_tensor = model.forward_features(xb)\n",
    "\n",
    "\n",
    "\n",
    "    B = x.shape[0]\n",
    "    errs = rel_err(y_rot_tensor, y_ref).view(num_samples, B).mean(dim=1)\n",
    "    return thetas, errs.detach().cpu().numpy()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def logits_invariance_error(model, x, angles=(0, 90, 180, 270)):\n",
    "    \"\"\"\n",
    "    Relative invariance error on logits after the invariant head.\n",
    "    \"\"\"\n",
    "    from torchvision.transforms.functional import rotate, InterpolationMode\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    x = x.to(device, non_blocking=True)\n",
    "\n",
    "    base = model(x)  # (B, C)\n",
    "    errs = {}\n",
    "    for a in angles:\n",
    "        xr = rotate(x, a, interpolation=InterpolationMode.BILINEAR)\n",
    "        yr = model(xr)\n",
    "        errs[a] = rel_err(base, yr).mean().item()\n",
    "    return errs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff297a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eda001c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_equivariance_batch() got an unexpected keyword argument 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 76\u001b[0m     thetas_out, errors \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_equivariance_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr2_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     plt\u001b[38;5;241m.\u001b[39mhlines(np\u001b[38;5;241m.\u001b[39mmean(errors), xmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi, linestyles\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdashed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(thetas_out, errors, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m\"\u001b[39m, ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, label\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/equi-act/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: check_equivariance_batch() got an unexpected keyword argument 'group'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch, numpy as np, matplotlib.pyplot as plt\n",
    "from escnn import gspaces, nn\n",
    "\n",
    "# --- group & test sampler ---\n",
    "r2_act = gspaces.rot2dOnR2(maximum_frequency=1)\n",
    "num_samples = 16\n",
    "thetas = np.linspace(0, 2*np.pi, num_samples, endpoint=True)\n",
    "elements = [r2_act.fibergroup.element(theta) for theta in thetas]\n",
    "\n",
    "g = gspaces.rot2dOnR2(N=-1)                   # SO(2)\n",
    "G = g.fibergroup\n",
    "ft_in = nn.FieldType(g, [g.trivial_repr])     # scalar input\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- model builders (same depth: conv -> act/norm -> bn -> conv) ---\n",
    "def build_norm_normbn(C=8, irreps=2):\n",
    "    irreps = [g.irrep(i) for i in range(irreps)]\n",
    "    ft = nn.FieldType(g, irreps*C)      # pure nontrivial => NormBN valid\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft, 3, padding=1, bias=True),\n",
    "        # nn.IIDBatchNorm2d(ft, affine=True),\n",
    "        # nn.NormNonLinearity(ft),\n",
    "        # nn.R2Conv(ft, ft, 3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "def build_gated_gnormbn(C=8):\n",
    "    feats = [g.irrep(0), g.irrep(1)]*C\n",
    "    gates = [g.trivial_repr]*len(feats)\n",
    "    ft_full = nn.FieldType(g, gates + feats)       # gates FIRST\n",
    "    ft_feat = nn.FieldType(g, feats)  # for batchnorm\n",
    "    len(ft_feat)\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft_full, 3, padding=1, bias=True),\n",
    "        nn.GatedNonLinearity1(ft_full, drop_gates=True),\n",
    "        # nn.FieldNorm(ft_feat, affine=True),\n",
    "        # nn.R2Conv(ft_feat, ft_feat, 3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "def build_tensorproduct_11_to_2(C=8):\n",
    "    ft1 = nn.FieldType(g, [g.irrep(1)]*C)          # uniform in\n",
    "    ft2 = nn.FieldType(g, [g.irrep(2)]*C)          # valid: 1⊗1 -> 2\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft1, 3, padding=1, bias=True),\n",
    "        nn.TensorProductModule(ft1, ft2, initialize=True),\n",
    "        # nn.FieldNorm(ft2, affine=True),\n",
    "        # nn.R2Conv(ft2, ft1, 3, padding=1, bias=False),  # keep width comparable\n",
    "    )\n",
    "\n",
    "def build_fourier_pointwise(C=8, L=3, N=16):\n",
    "    act = nn.FourierPointwise(g, channels=C, irreps=G.bl_irreps(L), N=N)\n",
    "    ft = act.out_type\n",
    "    return nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft, 3, padding=1, bias=True),\n",
    "        act,\n",
    "        nn.FieldNorm(ft, affine=True),\n",
    "        # nn.R2Conv(ft, ft, 3, padding=1, bias=False),\n",
    "    )\n",
    "\n",
    "models = {\n",
    "    \"Conv 2 irreps\":        build_norm_normbn(8),\n",
    "    \"Conv 3 irreps\":        build_norm_normbn(8, irreps=3),\n",
    "    \"Conv 4 irreps\":        build_norm_normbn(8, irreps=4),\n",
    "    \"Conv 2 irreps, N=32\":        build_norm_normbn(32, irreps=2),\n",
    "    \"Conv 3 irreps, N=32\":        build_norm_normbn(32, irreps=3),\n",
    "    \"Conv 4 irreps, N=32\":        build_norm_normbn(32, irreps=4),\n",
    "\n",
    "}\n",
    "\n",
    "# --- run equivariance tests ---\n",
    "x = torch.randn(1, 1, 256, 256)\n",
    "x = ft_in(x).to(device)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "for name, model in models.items():\n",
    "    model = model.to(device)\n",
    "    thetas_out, errors = check_equivariance_batch(x, model, group=r2_act, num_samples=num_samples)\n",
    "    plt.hlines(np.mean(errors), xmin=0, xmax=2*np.pi, linestyles='dashed')\n",
    "    plt.plot(thetas_out, errors, marker=\"o\", ms=3, label=name)\n",
    "plt.xlabel(\"rotation angle [rad]\"); plt.ylabel(\"equivariance error\")\n",
    "plt.title(\"Equivariance error vs. rotation (SO(2))\")\n",
    "plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c56a911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SO(2)_on_R2[(None, -1)]: {regular_[(0,)|(1,)|(2,)] (x16)}(80)],\n",
       " [SO(2)_on_R2[(None, -1)]: {irrep_0 (x1)}(1)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = nn.FourierPointwise(g, channels=16, irreps=G.bl_irreps(2), N=16)\n",
    "ft = act.out_type\n",
    "nn.SequentialModule(\n",
    "        nn.R2Conv(ft_in, ft, 3, padding=1, bias=True),\n",
    "        act,\n",
    "        nn.FieldNorm(ft, affine=True),\n",
    "        # nn.R2Conv(ft, ft, 3, padding=1, bias=False),\n",
    "    )\n",
    "ft, ft_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388ae9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new file: SO2_Nets/adaptive_fourier.py\n",
    "import torch\n",
    "from escnn import nn\n",
    "\n",
    "class SamplingBranch(torch.nn.Module):\n",
    "    def __init__(self, r2_act, in_type: nn.FieldType, N: int, hidden_ch: int = 16):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # small equivariant conv stack -> outputs N scalar trivial fields that we interpret as angles on S1\n",
    "        self.net = nn.SequentialModule(\n",
    "            nn.R2Conv(in_type, nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr]), kernel_size=3, padding=1, bias=False),\n",
    "            nn.IIDBatchNorm2d(nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr])),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.R2Conv(nn.FieldType(r2_act, hidden_ch * [in_type.fibergroup.trivial_repr]),\n",
    "                      nn.FieldType(r2_act, self.N * [in_type.fibergroup.trivial_repr]), kernel_size=1, padding=0, bias=True),\n",
    "        )\n",
    "        self.r2_act = r2_act\n",
    "        self.G = r2_act.fibergroup  # SO(2)\n",
    "\n",
    "    def forward(self, feat: nn.GeometricTensor, rep_rho):\n",
    "        # angles in [-pi, pi]\n",
    "        angles = torch.pi * torch.tanh(self.net(feat).tensor)  # [B, N, H, W]\n",
    "        # build A rows from angles and representation columns (quotient or regular)\n",
    "        # rep_rho expects a callable: g -> matrix R^{F}\n",
    "        A_rows = []\n",
    "        for k in range(self.N):\n",
    "            theta_k = angles[:, k:k+1, ...]  # [B,1,H,W]\n",
    "            gk = self.G.element(theta_k)     # broadcast element\n",
    "            # evaluate ρ(gk) δ̂  -> shape [B, F, H, W]\n",
    "            Ak = rep_rho(gk)                 # your helper that returns vectorized ρ(g)δ̂\n",
    "            A_rows.append(Ak)\n",
    "        A = torch.stack(A_rows, dim=1)  # [B, N, F, H, W]\n",
    "        return A\n",
    "\n",
    "class AdaptiveFourierPointwise(torch.nn.Module):\n",
    "    def __init__(self, r2_act, in_type: nn.FieldType, channels: int, irreps, function: str, N: int):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.function = function\n",
    "        self.r2_act = r2_act\n",
    "        # create a helper to map features to Fourier coeffs and back per ESCNN conventions\n",
    "        self.ft = nn.FourierTransform(in_type.gspace, irreps)\n",
    "        self.channels = channels\n",
    "\n",
    "    def forward(self, x: nn.GeometricTensor, A: torch.Tensor):\n",
    "        # x.tensor shape [B, Cin, H, W]; interpret as stacked bandlimited coeffs f̂ over channels/spatial\n",
    "        fhat = self.ft.forward(x)            # [B, C, F, H, W]\n",
    "        # Af̂: [B,N,F,H,W] x [B,C,F,H,W] -> [B,C,N,H,W]\n",
    "        y = torch.einsum('bnfhw,bcfhw->bcnhw', A, fhat)\n",
    "        # pointwise nonlinearity (ReLU/ELU) along N\n",
    "        if self.function.endswith('relu'):\n",
    "            y = torch.relu(y)\n",
    "        elif self.function.endswith('elu'):\n",
    "            y = torch.nn.functional.elu(y)\n",
    "        # (1/N)Aᵀ y: [B,C,F,H,W]\n",
    "        fhat_new = (1.0 / self.N) * torch.einsum('bnfhw,bcnhw->bcfhw', A, y)\n",
    "        # back to spatial field type\n",
    "        x_new = self.ft.inverse(fhat_new)\n",
    "        return x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bac44",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SO2' object has no attribute 'trivial_repr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m pad \u001b[38;5;241m=\u001b[39m kernel_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      8\u001b[0m non_linearity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp_relu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[43mSamplingBranch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr2_act\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# conv to feature_type before activation (as in your fixed variant)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     feature_repr \u001b[38;5;241m=\u001b[39m irreps \u001b[38;5;241m*\u001b[39m channels\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mSamplingBranch.__init__\u001b[0;34m(self, r2_act, in_type, N, hidden_ch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m=\u001b[39m N\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# small equivariant conv stack -> outputs N scalar trivial fields that we interpret as angles on S1\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequentialModule(\n\u001b[0;32m---> 11\u001b[0m     nn\u001b[38;5;241m.\u001b[39mR2Conv(in_type, nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [\u001b[43min_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfibergroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrivial_repr\u001b[49m]), kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     12\u001b[0m     nn\u001b[38;5;241m.\u001b[39mIIDBatchNorm2d(nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr])),\n\u001b[1;32m     13\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     14\u001b[0m     nn\u001b[38;5;241m.\u001b[39mR2Conv(nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, hidden_ch \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr]),\n\u001b[1;32m     15\u001b[0m               nn\u001b[38;5;241m.\u001b[39mFieldType(r2_act, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m*\u001b[39m [in_type\u001b[38;5;241m.\u001b[39mfibergroup\u001b[38;5;241m.\u001b[39mtrivial_repr]), kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mr2_act \u001b[38;5;241m=\u001b[39m r2_act\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG \u001b[38;5;241m=\u001b[39m r2_act\u001b[38;5;241m.\u001b[39mfibergroup\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SO2' object has no attribute 'trivial_repr'"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "irreps = [r2_act.irrep(0), r2_act.irrep(1), r2_act.irrep(2)]  # exclude trivial\n",
    "channels = 8\n",
    "N = 16\n",
    "kernel_size = 3\n",
    "cur_type = nn.FieldType(r2_act, [r2_act.trivial_repr] * channels)  # start from scalars\n",
    "pad = kernel_size // 2\n",
    "non_linearity = 'p_relu'\n",
    "sampler = SamplingBranch(r2_act, cur_type, N=N)\n",
    "for _ in range(2):\n",
    "    # conv to feature_type before activation (as in your fixed variant)\n",
    "    feature_repr = irreps * channels\n",
    "    feature_type = nn.FieldType(r2_act, feature_repr)\n",
    "    layers.append(nn.R2Conv(cur_type, feature_type, kernel_size=kernel_size, padding=pad, bias=False))\n",
    "\n",
    "    # build A and apply adaptive Fourier pointwise\n",
    "    act = nn.(r2_act, feature_type, channels=channels, irreps=irreps, function=non_linearity, N=N)\n",
    "    layers.append(nn.EquivariantModuleWrapper(feature_type, act, sampler))  # small wrapper that calls sampler then act\n",
    "\n",
    "    layers.append(nn.IIDBatchNorm2d(act.out_type))\n",
    "    cur_type = act.out_type\n",
    "\n",
    "nn.SequentialModule(*layers), cur_type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
