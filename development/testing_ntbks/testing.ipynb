{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:52:40.369318Z",
     "start_time": "2025-08-23T15:52:40.366502Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vojtasek/equi-act/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb23ffa623eae5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:52:43.073386Z",
     "start_time": "2025-08-23T15:52:41.046880Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"dpdl-benchmark/colorectal_histology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cb7309a01077b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:52:46.121900Z",
     "start_time": "2025-08-23T15:52:43.086231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "0\n",
      "6\n",
      "1\n",
      "3\n",
      "7\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "seen_labels = []\n",
    "for element in ds[\"train\"]:\n",
    "    if element[\"label\"] not in seen_labels:\n",
    "        print(element[\"label\"])\n",
    "        seen_labels.append(element[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36cd97fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SO(2)|[irrep_0]:1, SO(2)|[irrep_1]:2, SO(2)|[irrep_2]:2, SO(2)|[irrep_3]:2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from escnn import nn, gspaces\n",
    "\n",
    "o2 = gspaces.flipRot2dOnR2(maximum_frequency=3)\n",
    "o2.irreps\n",
    "so2 = gspaces.rot2dOnR2(maximum_frequency=3)\n",
    "so2.irreps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a878d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.78539816 1.57079633 2.35619449 3.14159265 3.92699082\n",
      " 4.71238898 5.49778714]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(+, 0.7853981633974483)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "thetas = np.linspace(0.0, 2*np.pi, 8, endpoint=False)\n",
    "print(thetas)\n",
    "o2.fibergroup.element((0,thetas[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ecc69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dda3a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 16200/16200 [00:00<00:00, 29396.62 examples/s]\n",
      "Generating test split: 100%|██████████| 5400/5400 [00:00<00:00, 48958.10 examples/s]\n",
      "Generating validation split: 100%|██████████| 5400/5400 [00:00<00:00, 49654.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"blanchon/EuroSAT_RGB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447cfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = ds[\"train\"]\n",
    "val_split = ds[\"validation\"]\n",
    "test_split = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35982d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16200, 5400, 5400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_split), len(val_split), len(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b75f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
      "Extracting data/modelnet10/ModelNet10.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos shape: torch.Size([32768, 3])\n",
      "labels shape: torch.Size([16])\n",
      "num graphs: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from datasets import load_dataset, ClassLabel\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Compose, Pad, Resize, RandomRotation, InterpolationMode, ToTensor, RandomVerticalFlip, RandomHorizontalFlip\n",
    "from torch_geometric.transforms import NormalizeScale, SamplePoints\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class ModelNet10PointClouds(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = \"./data/modelnet10\",\n",
    "        num_points: int = 2048,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "        val_split: float = 0.1,\n",
    "        shuffle_points: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.num_points = num_points\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_split = val_split\n",
    "        self.shuffle_points = shuffle_points\n",
    "\n",
    "        # Point-cloud transforms: normalize to unit sphere and sample N points per mesh\n",
    "        self.transform = Compose([\n",
    "            NormalizeScale(),\n",
    "            SamplePoints(self.num_points, remove_faces=True),\n",
    "        ])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # This triggers the download once; PyG handles the URL/zip/unpack for ModelNet10.\n",
    "        ModelNet(self.root, name=\"10\", train=True)\n",
    "        ModelNet(self.root, name=\"10\", train=False)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        train_full = ModelNet(self.root, name=\"10\", train=True, transform=self.transform)\n",
    "        test = ModelNet(self.root, name=\"10\", train=False, transform=self.transform)\n",
    "\n",
    "        # Split train into train/val\n",
    "        n_total = len(train_full)\n",
    "        n_val = int(self.val_split * n_total)\n",
    "        n_train = n_total - n_val\n",
    "        self.train_set, self.val_set = random_split(train_full, [n_train, n_val],\n",
    "                                                    generator=torch.Generator().manual_seed(42))\n",
    "        self.test_set = test\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size,\n",
    "                          shuffle=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size,\n",
    "                          shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size,\n",
    "                          shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "\n",
    "dm = ModelNet10PointClouds(num_points=2048, batch_size=16)\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "\n",
    "# Peek at one batch\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "# batch is a PyG Batch with fields like .pos (B*N x 3), .y (labels), and .batch (graph ids)\n",
    "print(\"pos shape:\", batch.pos.shape)     # (total_points_in_batch, 3)\n",
    "print(\"labels shape:\", batch.y.shape)    # (batch_size,)\n",
    "print(\"num graphs:\", batch.num_graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe29618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking Parameter Counts for Vector->Vector (Angular Dim should be 4) ---\n",
      "\n",
      "Kernel Size 3x3:\n",
      "  Total Learnable Weights: 7\n",
      "  Implied Radial Rings:    1.75  (Calculation: 7 / 4)\n",
      "\n",
      "Kernel Size 7x7:\n",
      "  Total Learnable Weights: 102\n",
      "  Implied Radial Rings:    25.5  (Calculation: 102 / 4)\n",
      "\n",
      "[CONCLUSION] The parameter count CHANGED.\n",
      "This confirms that the radial basis expands with kernel size,\n",
      "even though the angular constraints (symmetry) remain the same.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from escnn import gspaces\n",
    "from escnn import nn\n",
    "\n",
    "# 1. Setup the Group SO(2)\n",
    "r2_act = gspaces.rot2dOnR2(N=-1)\n",
    "\n",
    "# 2. Define Feature Types: Vector -> Vector\n",
    "# We know from theory this has an Angular Dimension of 4\n",
    "reprs = [r2_act.irrep(0), r2_act.irrep(1), r2_act.irrep(2), r2_act.irrep(3)]\n",
    "feat_in = nn.FieldType(r2_act, reprs)\n",
    "feat_out = nn.FieldType(r2_act, reprs)\n",
    "\n",
    "print(f\"--- Checking Parameter Counts for Vector->Vector (Angular Dim should be 4) ---\")\n",
    "\n",
    "# 3. Create Convolutions with DIFFERENT Kernel Sizes\n",
    "\n",
    "# Case A: Small Kernel (3x3)\n",
    "conv3 = nn.R2Conv(feat_in, feat_out, kernel_size=1, bias=True)\n",
    "params3 = conv3.basisexpansion.dimension()\n",
    "rings3 = float(params3) / 4  # We divide by 4 because we know the angular dim is 4\n",
    "\n",
    "# Case B: Large Kernel (7x7)\n",
    "# escnn automatically adds more radial rings to cover the larger space\n",
    "conv7 = nn.R2Conv(feat_in, feat_out, kernel_size=7, bias=True)\n",
    "params7 = conv7.basisexpansion.dimension()\n",
    "rings7 = float(params7) / 4\n",
    "\n",
    "# 4. Print Results\n",
    "print(f\"\\nKernel Size 3x3:\")\n",
    "print(f\"  Total Learnable Weights: {params3}\")\n",
    "print(f\"  Implied Radial Rings:    {rings3}  (Calculation: {params3} / 4)\")\n",
    "\n",
    "print(f\"\\nKernel Size 7x7:\")\n",
    "print(f\"  Total Learnable Weights: {params7}\")\n",
    "print(f\"  Implied Radial Rings:    {rings7}  (Calculation: {params7} / 4)\")\n",
    "\n",
    "# 5. Verification\n",
    "if params3 != params7:\n",
    "    print(\"\\n[CONCLUSION] The parameter count CHANGED.\")\n",
    "    print(\"This confirms that the radial basis expands with kernel size,\")\n",
    "    print(\"even though the angular constraints (symmetry) remain the same.\")\n",
    "else:\n",
    "    print(\"\\n[CONCLUSION] The parameter count stayed the same (Unexpected for standard settings).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dc00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from escnn import gspaces, nn\n",
    "\n",
    "so2 = gspaces.rot2dOnR2()\n",
    "\n",
    "in_type = nn.FieldType(so2, [so2.irrep(0),so2.irrep(2), so2.irrep(3)]*3 )\n",
    "in_type = in_type.sorted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551b061",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 12 (4052686431.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[13], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    def forward(self, input):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from escnn.group import *\n",
    "from escnn.gspaces import *\n",
    "from escnn.nn import FieldType\n",
    "from escnn.nn import GeometricTensor\n",
    "from escnn.nn import R2Conv\n",
    "from escnn.nn.modules.equivariant_module import EquivariantModule\n",
    "from escnn.nn import SequentialModule\n",
    "import escnn.nn as nn  # to avoid shadowing torch.nn as nn\n",
    "import escnn.gspaces as gspaces\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from escnn.gspaces import *\n",
    "from escnn.nn import FieldType\n",
    "from escnn.nn import GeometricTensor\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NormNonlinearityWithBN(EquivariantModule):\n",
    "    \n",
    "    def __init__(self, in_type: FieldType):\n",
    "        assert isinstance(in_type.gspace, GSpace)\n",
    "        super(NormNonlinearityWithBN, self).__init__()\n",
    "        self.gspace = in_type.gspace\n",
    "        self.in_type = in_type\n",
    "        self.out_type = in_type\n",
    "\n",
    "        self._relu = torch.relu\n",
    "        # first, iterate through the representations and sort them based on size. This will only effect the slicing, making it faster. Size use for the calulation of positions\n",
    "        self._indices = defaultdict()\n",
    "        position = 0\n",
    "        self._n_fields = 0\n",
    "        self._n_channels = 0\n",
    "        \n",
    "        seen = {}\n",
    "        # whether each group of fields is contiguous or not\n",
    "        self._contiguous = {}\n",
    "        for i, r in enumerate(self.in_type.representations):\n",
    "            self._n_fields += 1\n",
    "            if r.name not in seen:\n",
    "                self._n_channels += 1\n",
    "            if r.size != last_size:\n",
    "                # for faster slicing\n",
    "                if not r.size in self._contiguous:\n",
    "                    self._contiguous[r.size] = True\n",
    "                else:\n",
    "                    self._contiguous[r.size] = False\n",
    "            last_size = r.size\n",
    "            indices_start_end = (position, position+r.size)\n",
    "            position += r.size\n",
    "\n",
    "            if r.size in self._indices:\n",
    "                self._indices[r.size].append(indices_start_end)\n",
    "            else:\n",
    "                self._indices[r.size] = [indices_start_end]\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
